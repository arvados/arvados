---
layout: default
navsection: installguide
title: Install a compute node
...

h2. Install dependencies

First, "add the appropriate package repository for your distribution":{{ site.baseurl }}/install/install-manual-prerequisites.html#repos.

{% include 'note_python_sc' %}

On CentOS 6 and RHEL 6:

<notextile>
<pre><code>~$ <span class="userinput">sudo yum install perl python27-python-virtualenv fuse python27-python-arvados-python-client python27-python-arvados-fuse crunchrunner crunchstat arvados-docker-cleaner iptables ca-certificates</span>
</code></pre>
</notextile>

On other Red Hat-based systems:

<notextile>
<pre><code>~$ <span class="userinput">echo 'exclude=python2-llfuse' | sudo tee -a /etc/yum.conf</span>
~$ <span class="userinput">sudo yum install perl python-virtualenv fuse python-arvados-python-client python-arvados-fuse crunchrunner crunchstat arvados-docker-cleaner iptables ca-certificates</span>
</code></pre>
</notextile>

On Debian-based systems:

<notextile>
<pre><code>~$ <span class="userinput">sudo apt-get install perl python-virtualenv fuse python-arvados-python-client python-arvados-fuse crunchrunner crunchstat arvados-docker-cleaner iptables ca-certificates</span>
</code></pre>
</notextile>

{% include 'install_compute_docker' %}

h2. Set up SLURM

Install SLURM following "the same process you used to install the Crunch dispatcher":install-crunch-dispatch.html#slurm.

h2. Copy configuration files from the dispatcher (API server)

The @slurm.conf@ and @/etc/munge/munge.key@ files need to be identical across the dispatcher and all compute nodes. Copy the files you created in the "Install the Crunch dispatcher":install-crunch-dispatch.html step to this compute node.

{% include 'install_compute_fuse' %}

{% include 'install_docker_cleaner' %}

h2. Add a Crunch user account

Create a Crunch user account, and add it to the @fuse@ and @docker@ groups so it can use those tools:

<notextile>
<pre><code>~$ <span class="userinput">sudo useradd --groups fuse,docker crunch</span>
</code></pre>
</notextile>

The crunch user should have the same UID, GID, and home directory across all compute nodes and the dispatcher (API server).

h2. Tell the API server about this compute node

Load your API superuser token on the compute node:

<notextile>
<pre><code>
~$ <span class="userinput">HISTIGNORE=$HISTIGNORE:'export ARVADOS_API_TOKEN=*'</span>
~$ <span class="userinput">export ARVADOS_API_TOKEN=@your-superuser-token@</span>
~$ <span class="userinput">export ARVADOS_API_HOST=@uuid_prefix.your.domain@</span>
~$ <span class="userinput">unset ARVADOS_API_HOST_INSECURE</span>
</code>
</pre>
</notextile>

Then execute this script to create a compute node object, and set up a cron job to have the compute node ping the API server every five minutes:

<notextile>
<pre><code>
#!/bin/bash
set -e
if ! test -f /root/node.json ; then
    python - &lt;&lt;EOF
import arvados, json, socket
fqdn = socket.getfqdn()
hostname, _, domain = fqdn.partition('.')
node = arvados.api('v1').nodes().create(body={'hostname': hostname, 'domain': domain}).execute()
with open('/root/node.json', 'w') as node_file:
    json.dump(node, node_file, indent=2)
EOF

    # Make sure /dev/fuse permissions are correct (the device appears after fuse is loaded)
    chmod 1660 /dev/fuse && chgrp fuse /dev/fuse
fi

UUID=`grep \"uuid\" /root/node.json  |cut -f4 -d\"`
PING_SECRET=`grep \"ping_secret\" /root/node.json  |cut -f4 -d\"`

if ! test -f /etc/cron.d/node_ping ; then
    echo "*/5 * * * * root /usr/bin/curl -k -d ping_secret=$PING_SECRET https://$ARVADOS_API_HOST/arvados/v1/nodes/$UUID/ping" > /etc/cron.d/node_ping
fi

/usr/bin/curl -k -d ping_secret=$PING_SECRET https://$ARVADOS_API_HOST/arvados/v1/nodes/$UUID/ping?ping_secret=$PING_SECRET
</code>
</pre>
</notextile>

And remove your token from the environment:

<notextile>
<pre><code>
~$ <span class="userinput">unset ARVADOS_API_TOKEN</span>
~$ <span class="userinput">unset ARVADOS_API_HOST</span>
</code>
</pre>
</notextile>
